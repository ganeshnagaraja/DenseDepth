# train.py Config - Training
train:
  # Synthetic datasets with ground truth labelsinp, output shapes :
  datasetsTrain:
      - normals: 'data/datasets/train/stemless-plastic-champagne-glasses-lying-flat-2-train/source-files/camera-normals'
        images: 'data/datasets/train/stemless-plastic-champagne-glasses-lying-flat-2-train/source-files/rgb-imgs'
        labels: 'data/datasets/train/stemless-plastic-champagne-glasses-lying-flat-2-train/source-files/depth-imgs-rectified'
      - normals: 'data/datasets/train/square-clear-plastic-bottle-lying-flat-2-train/source-files/camera-normals'
        images: 'data/datasets/train/square-clear-plastic-bottle-lying-flat-2-train/source-files/rgb-imgs'
        labels: 'data/datasets/train/square-clear-plastic-bottle-lying-flat-2-train/source-files/depth-imgs-rectified'
      - normals: 'data/datasets/train/hearts-in-containers-2-train/source-files/camera-normals'
        images: 'data/datasets/train/hearts-in-containers-2-train/source-files/rgb-imgs'
        labels: 'data/datasets/train/hearts-in-containers-2-train/source-files/depth-imgs-rectified'

  # Synthetic datasets with ground truth labels - 10% split of train
  datasetsVal:
      - normals: 'data/datasets/val/stemless-plastic-champagne-glasses-lying-flat-2-val/source-files/camera-normals'
        images: 'data/datasets/val/stemless-plastic-champagne-glasses-lying-flat-2-val/source-files/rgb-imgs'
        labels: 'data/datasets/val/stemless-plastic-champagne-glasses-lying-flat-2-val/source-files/depth-imgs-rectified'
      - normals: 'data/datasets/val/square-clear-plastic-bottle-lying-flat-2-val/source-files/camera-normals'
        images: 'data/datasets/val/square-clear-plastic-bottle-lying-flat-2-val/source-files/rgb-imgs'
        labels: 'data/datasets/val/square-clear-plastic-bottle-lying-flat-2-val/source-files/depth-imgs-rectified'
      - normals: 'data/datasets/val/hearts-in-containers-2-val/source-files/camera-normals'
        images: 'data/datasets/val/hearts-in-containers-2-val/source-files/rgb-imgs'
        labels: 'data/datasets/val/hearts-in-containers-2-val/source-files/depth-imgs-rectified'

 # Training/Validation Params
  model: 'rednet' # Possible values - [ 'rednet', 'deeplab_xception', 'deeplab_resnet']
  batchSize: 32
  numEpochs: 500
  imgHeight: 256
  imgWidth: 256
  numClasses: 1
  numInputChannels: 3 # Num of channels in input image. Normals+Depth = 4 channels, Only_Normals = 3 channles, Grayscale = 1 channel.
  numWorkers: 32 # Num of workers used in the dataloader
  logsDir: 'logs' # Directory where logs of each exp will be saved.
  useMaskforLoss: False # Whether to calc loss over entire image, or only over masked area.
  concat_depth: False # Whether to concat depth with normals as input or use only normals.
  loss_type: 'l1' # Possible values - ['l1', 'l2']. Type of loss to use for back propagation
  normalize_depth: True # whether the labels and outputs must be de-normalized or not
  percentageDataForTraining: 1.0 # The percentage of images in dataset to be used for training. Rest used for validation.
  validationBatchSize: 50
  percentageDataForValidation: 1.0
  testBatchSize: 50
  outputStride: 16 # Possible values - [8, 16]. Output stride for deeplabv3 model. Smaller values give finer details in output mask.


  min_depth: 0.0
  max_depth: 3.0

  continueTraining: True  # If true, continue training from a checkpoint
  pathPrevCheckpoint: 'logs/exp-004/checkpoints/checkpoint-epoch-0200.pth' # Path to .pth checkpoint file to load to continue training from
  initOptimizerFromCheckpoint: False  # Re-Initialize optimizer's state from checkpoint. NOTE: when this is enabled, value of learningRate will be overridden with value from checkpoint.
  loadEpochNumberFromCheckpoint: False # If true, the epoch/iter numbering will start from the checkpoint's last epoch num.

  saveImageInterval: 5 # Log output images to tensorboard every saveImageInterval epochs
  testInterval: 1 # Run on test set every nTestInterval epochs. Keep at 0 to skip tests.
  saveModelInterval: 5 # Save the model checkpoints every N epochs


  # Optimizer Params
  optimAdam:
    learningRate: 0.001
    beta1: 0.9
    beta2: 0.999
    weightDecay: 0 # Other values: 0.0001
  optimSgd:
    learningRate: 1e-3  # 2e-3
    momentum: 0.9
    weight_decay: 4e-4 #5e-4
  lrScheduler: 'StepLR' # Possible Values - ['', 'StepLR', 'ReduceLROnPlateau', 'lr_poly', 'LambdaLR'] # lr_poly used for deeplabv3+
  lrSchedulerStep:
    step_size: 5
    gamma: 0.8
  lrSchedulerPlateau:
    factor: 0.8
    patience: 25
    verbose: True
  lrPoly:
    epochSize: 1 # After these many epochs, change learning rate
    decay: 0.7
  LambdaLR: # rednet
    lr_decay_rate: 0.8
    lr_epoch_per_decay: 10

# eval.py Config - Validation/Testing Inference
eval:
  # Synthetic datasets with ground truth labels
  # Used as validation set
  datasetsSynthetic:
    # - images: 'data/datasets/val/stemless-plastic-champagne-glasses-lying-flat-val/source-files/rgb-imgs'
    #   labels: 'data/datasets/val/stemless-plastic-champagne-glasses-lying-flat-val/source-files/depth-imgs-rectified'

  # Datasets of real images, no labels available
  # Used as Test set
  datasetsReal:
    - images: 'data/datasets/test/realsense-demo-table/source-files/rgb-imgs'
      labels: 'data/datasets/test/realsense-demo-table/source-files/depth-imgs'

  # Params
  mode: 'depth'
  model: 'densenet' # Possible values: ['rednet', 'unet', 'deeplab_xception', 'deeplab_resnet']
  numClasses: 1
  numInputChannels: 3
  batchSize: 2
  outputStride: 16
  imgHeight: 256
  imgWidth: 256
  numWorkers: 8 # Num of workers used in the dataloader
  pathWeightsFile: 'logs/volta2_densenet/checkpoint-epoch-0200.pth' # Path to the checkpoint to be loaded
  resultsDirSynthetic: 'data/results/test-synthetic' # The dir to which results on synthetic images will be stored
  resultsDirReal: 'data/results/test-real'  # The dir to which results on real images will be stored
  resultsWeightsSubDir: 'occlusion-weights' # The prediction of model will be converted to occlusion weights (for depth2depth) in this subfolder within each results folder
  resultsWeightsVizSubDir: 'occlusion-weights-viz' # The visualization of the occlusion weights will be saved in this subfolder within resultsWeightsSubDir